{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algo 2 ‚Äì Python\n",
    "\n",
    "## Cours 11\n",
    "\n",
    "###  Master Humanit√©s Num√©riques du CESR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex et parseurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aujourd‚Äôhui deux notions/outils qui pourront vous √™tre utiles :‚ÄØles expressions r√©guli√®res (regex) et les parseurs. On aura sans doute pas le temps de tout voir en d√©tail, vous pourrez poursuivre par vous-m√™me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex\n",
    "\n",
    "Le langage formel des expressions r√©guli√®res (aka regex, *regular expression* en anglais) est un outil puissant et expressif pour la recherche de cha√Ænes de caract√®res. Il permet de d√©finir un motif (*pattern*) de recherche qui porte sur une cha√Æne de caract√®res.\n",
    "\n",
    "Exemples :‚ÄØ\n",
    " - \"tubes?\" -> cha√Æne de caract√®re \"tube\" ou \"tubes\"\n",
    " - \"[a-z]+eur\\b\" -> cha√Æne se terminant par \"eur\"\n",
    " - \"\\d{4}-\\d{2}-\\d{2}\" -> date au format ISO‚ÄØ8601 : 2024-03-27 (4 entiers, un tiret, 2 entiers, un tiret, 2 entiers)\n",
    " - ‚Ä¶\n",
    "\n",
    "Les expressions r√©guli√®res sont support√©es par la plupart de langages de programmation. Vous les retrouvez dans les √©diteurs de texte, dans les traitements de textes et dans pas mal de moteurs de recherche.  \n",
    "Comme c‚Äôest tr√®s utilis√© il existe beaucoup beaucoup de sites bien faits :\n",
    "\n",
    "- [https://regex101.com/](https://regex101.com/) est un site tr√®s bien fait pour se former et tester des regex. Allons y tester les exemples vus plus haut.\n",
    "- Il y a de tr√®s bons supports de documentation sur les regex, autant en profiter. Par exemple [https://quickref.me/regex.html](https://quickref.me/regex.html)  \n",
    "- Vous pouvez aussi vous auto former avec [https://regexone.com/](https://regexone.com/) ou le magnifique [https://regexcrossword.com](https://regexcrossword.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En python √ßa se passe avec le module `re` (livr√© avec la distribution standard) ou `regex` (module externe √† installer). On va s‚Äôen tenir √† `re` ici.\n",
    "\n",
    "- `re` est un module important, vous devez en lire la [documentation](https://docs.python.org/3/library/re.html), absolument\n",
    "- La doc officielle est parfois aride, ce [howto](https://docs.python.org/3/howto/regex.html) r√©dig√© par A.M. Kuchling est plus digeste\n",
    "\n",
    "A minima vous devez conna√Ætre les fonctions :\n",
    "\n",
    "- `findall` : trouve toutes les occurences du motif, retourne une liste de cha√Ænes trouv√©es\n",
    "- `search` : trouve le motif, retourne un objet Match, None sinon\n",
    "- `match` : d√©termine si le motif est pr√©sent au d√©but de la cha√Æne, retourne un objet Match, None sinon\n",
    "- `split` : d√©coupe une cha√Æne selon un motif, retourne une liste de cha√Ænes\n",
    "- `sub` : remplace les occurences d'un motif par une cha√Æne de remplacement\n",
    "- `compile` : compilation d'un motif (pattern), retourne un objet Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pas trouv√©\n"
     ]
    }
   ],
   "source": [
    "## Exemple avec \"cha√Æne se terminant en 'eur'\"\n",
    "\n",
    "import re\n",
    "\n",
    "first_str = \"Avec toutes ces histoires j‚Äôai peur de la clameur de la foule.\"\n",
    "second_str = \"Avec toutes ces histoires j‚Äôai envie d‚Äôune tasse de caf√©.\"\n",
    "if re.search(r\"[a-z]+eur\\b\", second_str):\n",
    "    print(\"Trouv√©\")\n",
    "else:\n",
    "    print(\"Pas trouv√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objet `Match`\n",
    "`re.search` et `re.match` renvoient un objet de type `re.Match`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.Match"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = re.match(r'\\w', 'spam')\n",
    "type(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le motif est trouv√©, l'objet est √©valu√© comme vrai (*truthy*) s'il est test√© mais il contient plus d'informations :\n",
    "\n",
    "- `m.group()` la cha√Æne trouv√©e (match√©e)\n",
    "- `m.start()` l'indice de la position initiale de la cha√Æne\n",
    "- `m.end()` l'indice de la position finale de la cha√Æne\n",
    "- `m.span()` le tuple indice d√©but, fin de la cha√Æne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la\n"
     ]
    }
   ],
   "source": [
    "m = re.search(r\"l[ae]s?\", \"Apr√®s la pluie, le beau temps\")\n",
    "print(m.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le motif comporte des groupes de capture :\n",
    "- `m.group(1)` renvoie la cha√Æne correspond au 1er groupe, etc.\n",
    "- `m.groups()` renvoie un tuple comportant autant d'√©l√©ments qu'il y a de groupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('la', 'pluie')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = re.search(r\"(l[ae]s?)\\s(\\w+)\", \"Apr√®s la pluie, le beau temps\")\n",
    "m.groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è  Exo ‚úçÔ∏è\n",
    "\n",
    "- Trouver les noms de personnes ou les noms de lieux dans ces paragraphes :\n",
    "  \n",
    "  ¬´ Famed American artist and sculptor Richard Serra, known for turning curving walls of rusting steel and other malleable materials into large-scale pieces of outdoor artwork that are now dotted across the world, died Tuesday at his home in Long Island, New York. He was 85.\n",
    "\n",
    "    Considered one of his generation's most preeminent sculptors, the San Francisco native originally studied painting at Yale University but turned to sculpting in the 1960s, inspired by trips to Europe.\n",
    "\n",
    "    His death was confirmed Tuesday night by his lawyer, John Silberman, whose firm is based in New York. He said the cause of death was pneumonia. ¬ª  \n",
    "  (extrait de https://www.npr.org/2024/03/26/1241104634/richard-serra-dead)\n",
    "- Trouver les liens hypertextes dans la page `https://www.reddit.com/r/Python/` et les afficher sous la forme `ancre: url`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Famed', 'American')\n",
      "('Richard', 'Serra')\n",
      "('Long', 'Island')\n",
      "('New', 'York')\n",
      "('San', 'Francisco')\n",
      "('Yale', 'University')\n",
      "('John', 'Silberman')\n",
      "('New', 'York')\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "first_str = \"\"\"Famed American artist and sculptor Richard Serra, known for turning curving walls of rusting steel and other malleable materials into large-scale pieces of outdoor artwork that are now dotted across the world, died Tuesday at his home in Long Island, New York. He was 85.\n",
    "\n",
    "Considered one of his generation's most preeminent sculptors, the San Francisco native originally studied painting at Yale University but tured to sculpting in the 1960s, inspired by trips to Europe.\n",
    "\n",
    "His death was confirmed Tuesday night by his lawyer, John Silberman, whose firm is based in New York. He said the cause of death was pneumonia.\"\"\"\n",
    "\n",
    "for match in re.findall(r\"([A-Z]\\w+) ([A-Z]\\w+)\", first_str):\n",
    "    print(match)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r/LearnPython : /r/LearnPython/\n",
      "Book: Automate the Boring Stuff with Python : https://automatetheboringstuff.com/\n",
      "Book: Think Python : http://www.greenteapress.com/thinkpython2/index.html\n",
      "Book: Fluent Python : https://www.oreilly.com/library/view/fluent-python-2nd/9781492056348/\n",
      "Learn Python on Excercism : https://exercism.org/tracks/python\n",
      "Invent Your Own Computer Games with Python : http://inventwithpython.com/\n",
      "PyMotW: Python Module of the Week : https://pymotw.com/3/\n",
      "Beginner&#39;s Guide Reference : http://wiki.python.org/moin/BeginnersGuide\n",
      "Five life jackets to throw to the new coder (things to do after getting a handle on python) : https://learnbyexample.github.io/curated-resources/python-intermediate/\n",
      "Full Stack Python : http://www.fullstackpython.com/\n",
      "Learn By Example &quot;I know Python basics, what next?&quot; blog post : https://learnbyexample.github.io/curated-resources/python-intermediate/\n",
      "Test-Driven Development with Python : http://www.obeythetestinggoat.com/pages/book.html\n",
      "Program Arcade Games : /http://programarcadegames.com/\n",
      "Python for Scientists and Engineers : http://pythonforengineers.com/python-for-scientists-and-engineers/\n",
      "Dan Bader&#39;s Tips and Trickers : https://dbader.org/\n",
      "JetBrain&#39;s &quot;What does this package do?&quot; series on YouTube : https://www.youtube.com/playlist?list=PLCTHcU1KoD99ZWRvzAGrvF6ZBCrkmZk4t\n",
      "Python Cheatsheet : https://github.com/gto76/python-cheatsheet\n",
      "Python Crash Course cheatsheet : https://ehmatthes.github.io/pcc_3e/cheat_sheets/\n",
      "Scientific Python cheatsheet : https://ipgp.github.io/scientific_python_cheat_sheet/\n",
      "Python RegEx cheatsheet : https://learnbyexample.github.io/python-regex-cheatsheet/\n",
      "Python Discord Resources : https://pythondiscord.com/pages/resources\n",
      "Python Discord&#39;s YouTube channel : https://www.youtube.com/pythondiscord\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get(\"https://www.reddit.com/r/Python/\")\n",
    "if r:\n",
    "    content = r.text\n",
    "    matches = re.findall(r\"href=\\\"([^\\\"]+)\\\">([^<]+?)</a>\", content)\n",
    "    for it in matches:\n",
    "        print(f\"{it[1]} : {it[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parseurs\n",
    "\n",
    "Dans ce notebook nous utiliserons le parseur [lxml](http://lxml.de/) qui est un binding de libxml2 et [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/) \n",
    "\n",
    "Cette partie date de d√©cembre 2020. Je me suis permis de la reprendre telle quelle. L‚Äôexemple avec les chansons de NPR fonctionne toujours. Nous allons tout de m√™me essayer de le mettre √† jour avec les chansons de 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Parser de l'html\n",
    "\n",
    "Beautiful Soup nous permet de parser simplement du contenu html. M√™me si le contenu est mal form√©, le module bs reconstitue un arbre et offre des fonctions faciles √† utiliser pour parcourir l'arbre ou y rechercher des √©l√©ments.  \n",
    "Beautiful Soup n'est pas un parseur, il utilise les parseurs et offre une API simplifi√©e √† ses utilisateurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous travaillerons directement avec du contenu en ligne √† l'aide du module `requests`. Si vous ne l'avez pas en magasin, installez le.  \n",
    "D√©cembre c'est le mois des listes, nous nous attacherons √† la liste des 100 meilleures chansons de l'ann√©e de NPR la radio publique am√©ricaine :¬†https://www.npr.org/2020/12/03/931771524/the-100-best-songs-of-2020-page-1  \n",
    "Allez y faire un tour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.npr.org/2020/12/03/931771524/the-100-best-songs-of-2020-page-1\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voil√† nous avons maintenant un objet `soup` de classe Beautiful Soup.  \n",
    "La [doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) est tr√®s claire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>NPR's 100 Best Songs Of 2020, Ranked : NPR</title>\n",
      "title\n",
      "NPR's 100 Best Songs Of 2020, Ranked : NPR\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.npr.org/2020/12/03/931771524/the-100-best-songs-of-2020-page-1\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, 'lxml')\n",
    "# je cherche l'√©lement avec le tag 'title'\n",
    "print(soup.title)\n",
    "# le tag de l'√©l√©ment\n",
    "print(soup.title.name)\n",
    "# le contenu textuel de l'√©l√©ment\n",
    "print(soup.title.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche √† r√©cup√©rer la liste des 100 chansons :¬†rang, titre, interpr√®te. Puis on les affichera par ordre croissant.  \n",
    "Il faut inspecter le code source et rep√©rer les √©lements html et les classes utilis√©es pour le contentu qui nous int√©resse.  \n",
    "Exemple avec le premier, enfin le 100√®me :¬†BTS. Dynamite. üé∂ Cos I‚Ä¶ I‚Ä¶ I'm in the stars tonight üé∏ üé∂\n",
    "\n",
    "```html\n",
    "<h6 class=\"edTag\"><a id=\"bts\" class=\"anchor\"> </a>100.</h6>\n",
    "<h3 class=\"edTag\">BTS</h3>\n",
    "<h3 class=\"edTag\">\"Dynamite\"</h3>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100.\n",
      " 99.\n",
      " 98.\n",
      " 97.\n",
      " 96. \n",
      " 95.\n",
      " 94. \n",
      " 93.\n",
      " 92.\n",
      " 91.\n",
      " 90.\n",
      " 89.\n",
      " 88.\n",
      " 87.\n",
      " 86.\n",
      " 85.\n",
      " 84.\n",
      " 83.\n",
      " 82.\n",
      " 81.\n"
     ]
    }
   ],
   "source": [
    "# Exemple pour r√©cup√©rer les √©l√©ments h6¬†class='edTag'\n",
    "for item in soup.find_all('h6', attrs={'class':'edTag'}):\n",
    "    print(item.text)\n",
    "# on peut aussi utiliser la notation suivante\n",
    "#for item in soup.find_all('h6', class_=\"edTag\"):\n",
    "#    print(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è  Exo ‚úçÔ∏è\n",
    "Maintenant √† vous de jouer. Il faut parcourir la [doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) pour trouver la fonction qui vous permettra de r√©cup√©rer les deux √©l√©ments h3 suivants et seulement ceux-l√†. \n",
    "Je vous laisse chercher un peu ![Alt Text](https://media.giphy.com/media/l2SpZkQ0XT1XtKus0/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encore un peu ![on cherche](https://media.giphy.com/media/JO9pi3EeHzyBu5YNMK/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100., BTS, \"Dynamite\"\n",
      " 99., Sturgill Simpson, \"Living The Dream\"\n",
      " 98., Ariana Grande, \"pov\"\n",
      " 97., Busta Rhymes (feat. Kendrick Lamar), \"Look Over Your Shoulder\"\n",
      " 96. , Chicano Batman , \"Color my life\"\n",
      " 95., Tiwa Savage , \"Dangerous Love (DJ Tunez & D3an Remix)\"\n",
      " 94. , Breland (feat. Sam Hunt), \"My Truck (Remix)\"\n",
      " 93., Leon Bridges (feat. Terrace Martin), \"Sweeter\"\n",
      " 92., Yumi Zouma, \"Cool For A Second\"\n",
      " 91., Hayley Williams, \"Simmer\"\n",
      " 90., The 1975, \"If You're Too Shy (Let Me Know)\"\n",
      " 89., Swamp Dogg, \"Billy\"\n",
      " 88., Roomful Of Teeth, \"Just Constellations No. 1, The Opening Constellation (Summer)\"\n",
      " 87., GIVƒíON, \"Still Your Best\"\n",
      " 86., Moneybagg Yo, \"Said Sum\"\n",
      " 85., Rita Indiana (feat. Kiko El Crazy), \"Mandinga Times\"\n",
      " 84., Ashnikko (feat. Grimes), \"Cry\"\n",
      " 83., Ultra√≠sta, \"Tin King\"\n",
      " 82., Sweeping Promises, \"Hunger For A Way Out\"\n",
      " 81., Arlo McKinley, \"Die Midwestern\"\n"
     ]
    }
   ],
   "source": [
    "for item in soup.find_all('h6', attrs={'class':'edTag'}):\n",
    "    rank = item.text\n",
    "    h3s = item.find_next_siblings('h3', attrs={'class':'edTag'}, limit=2)\n",
    "    artist = h3s[0].text\n",
    "    title = h3s[1].text\n",
    "    print(f\"{rang}, {artist}, {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è  Exo ‚úçÔ∏è\n",
    "\n",
    "C'est bien mais pas suffisant. Il reste :\n",
    "  1. nettoyer les rangs, c-a-d supprimmer le point qui tra√Æne √† la fin et l'espace des fois.\n",
    "  2. stocker les infos dans une donn√©e structur√©e. Utilisez une classe √† vous ou plus simple un `namedtuple`\n",
    "  3. faire l'op√©ration pour toutes les pages web afin d'avoir le classement de 1 √† 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://www.npr.org/2020/12/03/931771524/the-100-best-songs-of-2020-page-1\",\n",
    "    \"https://www.npr.org/2020/12/03/934634561/the-100-best-songs-of-2020-page-2?utm_source=page1&utm_campaign=next&utm_term=bottom&utm_medium=internal\",\n",
    "    \"https://www.npr.org/2020/12/03/934634607/the-100-best-songs-of-2020-page-3?utm_source=page2&utm_campaign=next&utm_term=bottom&utm_medium=internal\",\n",
    "    \"https://www.npr.org/2020/12/03/934634855/the-100-best-songs-of-2020-page-4?utm_source=page3&utm_campaign=next&utm_term=bottom&utm_medium=internal\",\n",
    "    \"https://www.npr.org/2020/12/03/934634998/the-100-best-songs-of-2020-page-5?utm_source=page4&utm_campaign=next&utm_term=bottom&utm_medium=internal\"\n",
    "]\n",
    "# √† vous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Cardi B (feat. Megan Thee Stallion) \"WAP\"\n",
      "2 Christine and the Queens \"People, I've been sad\"\n",
      "3 Megan Thee Stallion (feat. Beyonc√©) \"Savage Remix\"\n",
      "4 Mickey Guyton \"Black Like Me\"\n",
      "5 Bad Bunny (feat. Jowell & Randy and √ëengo Flow) \"Safaera\"\n",
      "6 Adrianne Lenker \"anything\"\n",
      "7 Bob Dylan \"Murder Most Foul\"\n",
      "8 Thundercat \"Dragonball Durag\" \n",
      "9 Ana Tijoux \"Antifa Dance\"\n",
      "10 Adia Victoria \"South Gotta Change\"\n",
      "11 Sam Hunt \"Hard to Forget\"\n",
      "12 Jazmine Sullivan \"Lost One\"\n",
      "13 Caylee Hammack \"Small Town Hypocrite\"\n",
      "14 J Hus (feat. Koffee) \"Repeat\"\n",
      "15 Perfume Genius \"On The Floor\"\n",
      "16 Chris Stapleton \"Starting Over\"\n",
      "17 Phoebe Bridgers \"I Know The End\"\n",
      "18 V√≠kingur √ìlafsson \"The Arts and the Hours\"\n",
      "19 Joshua Redman, Brad Mehldau, Christian McBride & Brian Blade \"Right Back Round Again\"\n",
      "20 SZA (feat. Ty Dolla $ign) \"Hit Different\" \n",
      "21 Lil Baby \"The Bigger Picture\"\n",
      "22 Taylor Swift \"invisible string\"\n",
      "23 Childish Gambino \"47.48\"\n",
      "24 Fiona Apple \"I Want You To Love Me\"\n",
      "25 Goodie Mob \"4 My Ppl\"\n",
      "26 The Chicks \"Gaslighter\"\n",
      "27 Noname \"Song 33\"\n",
      "28 Stephanie Lambring \"Joy of Jesus\"\n",
      "29 Lianne La Havas \"Can't Fight\"\n",
      "30 William Prince \"Gospel First Nation\"\n",
      "31 Inbal Segev & London Philharmonic Orchestra \"DANCE, I. when you're broken open\"\n",
      "32 Angelica Garcia \"Agua de Rosa\"\n",
      "33 SAULT \"Wildfires\"\n",
      "34 Jason Isbell and The 400 Unit \"Letting You Go\"\n",
      "35 Kllo  \"Still Here\"\n",
      "36 Immanuel Wilkins  \"Ferguson - An American Tradition\"\n",
      "37 Sun-El Musician (feat. Azana) \"Uhuru\"\n",
      "38 Soccer Mommy \"circle the drain\"\n",
      "39 Dua Lipa  \"Break My Heart\"\n",
      "40 Lil Baby (feat. 42 Dugg) \"We Paid\"\n",
      "41 Tyler Childers \"Long Violent History\"\n",
      "42 Clarice Jensen \"Holy Mother\"\n",
      "43 RMR \"Rascal\"\n",
      "44 Chucky73 & Fetti031 \"Dili\"\n",
      "45 Lakecia Benjamin (feat. Marcus Strickland & Brandee Younger) \"Going Home\"\n",
      "46 Deep Sea Diver \"Stop Pretending\"\n",
      "47 Jayda G \"Both Of Us\"\n",
      "48 Helado Negro (feat. Xenia Rubinos) \"I Fell In Love\"\n",
      "49 Arlo Parks \"Eugene\"\n",
      "50 Romy \"Lifetime\"\n",
      "51 Emma Ruth Rundle & Thou \"Ancestral Recall\"\n",
      "52 Bad Moves \"Local Radio\"\n",
      "53 Jeff Parker \"Go Away\"\n",
      "54 Freddie Gibbs / The Alchemist (feat. Rick Ross) \"Scottie Beam\"\n",
      "55 Shemekia Copeland \"Walk Until I Ride\"\n",
      "56 Steady Holiday \"Living Life\"\n",
      "57 Disclosure (feat. slowthai & Amin√©) \"My High\"\n",
      "58 Moses Boyd (feat. Joe Armon-Jones) \"2 Far Gone\"\n",
      "59 Fontaines D.C. \"A Hero's Death\"\n",
      "60 City Girls \"Jobs\"\n",
      "61 Sam Sweeney \"Steppy Downs Road\"\n",
      "62 Moor Jewelry \"Look Alive\"\n",
      "63 Lido Pimienta \"Eso Que Tu Haces\"\n",
      "64 Sarah Jarosz \"Johnny\"\n",
      "65 Rolf Lislevand \"Tombeau pour Mesdemoiselles De Vis√©e\"\n",
      "66 Meet Me @ The Altar \"Garden\"\n",
      "67 La Do√±a \"Qui√©n Me La Paga\"\n",
      "68 Patrice Roberts \"Tender\"\n",
      "69 Joy Oladokun \"i see america\"\n",
      "70 Aly & AJ \"Joan of Arc on the Dance Floor\"\n",
      "71 Ruston Kelly \"Radio Cloud\"\n",
      "72 Zara McFarlane \"Everything Is Connected\"\n",
      "73 Ashley McBryde \"Hang In There Girl\"\n",
      "74 Xavier Om√§r  \"SURF\"\n",
      "75 Mireya Ramos  \"Angelitos Negros\"\n",
      "76 Jessie Ware \"Save A Kiss\"\n",
      "77 Hum \"Waves\"\n",
      "78 Terrace Martin, Robert Glasper, 9th Wonder & Kamasi Washington (feat. Phoelix) \"Freeze Tag\"\n",
      "79 BeatKing (feat. Queendom Come) \"Then Leave\"\n",
      "80 Popcaan (feat. Drake & PARTYNEXTDOOR) \"TWIST & TURN\"\n",
      "81 Arlo McKinley \"Die Midwestern\"\n",
      "82 Sweeping Promises \"Hunger For A Way Out\"\n",
      "83 Ultra√≠sta \"Tin King\"\n",
      "84 Ashnikko (feat. Grimes) \"Cry\"\n",
      "85 Rita Indiana (feat. Kiko El Crazy) \"Mandinga Times\"\n",
      "86 Moneybagg Yo \"Said Sum\"\n",
      "87 GIVƒíON \"Still Your Best\"\n",
      "88 Roomful Of Teeth \"Just Constellations No. 1, The Opening Constellation (Summer)\"\n",
      "89 Swamp Dogg \"Billy\"\n",
      "90 The 1975 \"If You're Too Shy (Let Me Know)\"\n",
      "91 Hayley Williams \"Simmer\"\n",
      "92 Yumi Zouma \"Cool For A Second\"\n",
      "93 Leon Bridges (feat. Terrace Martin) \"Sweeter\"\n",
      "94 Breland (feat. Sam Hunt) \"My Truck (Remix)\"\n",
      "95 Tiwa Savage  \"Dangerous Love (DJ Tunez & D3an Remix)\"\n",
      "96 Chicano Batman  \"Color my life\"\n",
      "97 Busta Rhymes (feat. Kendrick Lamar) \"Look Over Your Shoulder\"\n",
      "98 Ariana Grande \"pov\"\n",
      "99 Sturgill Simpson \"Living The Dream\"\n",
      "100 BTS \"Dynamite\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Song():\n",
    "    \"\"\"\n",
    "    A‚ÄØsong with 3 infos : artist, title, rank (according to NPR list)\n",
    "    \"\"\"\n",
    "    def __init__(self, artist, title, rank):\n",
    "        self.artist = artist\n",
    "        self.title = title\n",
    "        self.rank = rank\n",
    "\n",
    "songs = []\n",
    "for url in urls:\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    for item in soup.find_all('h6', attrs={'class':'edTag'}):\n",
    "        rank = item.text.rstrip(\". \").lstrip()\n",
    "        h3s = item.find_next_siblings('h3', attrs={'class':'edTag'}, limit=2)\n",
    "        artist = h3s[0].text\n",
    "        title = h3s[1].text\n",
    "        songs.append(Song(artist, title, rank))\n",
    "\n",
    "for song in sorted(songs, key=lambda x:int(x.rank)):\n",
    "    print(song.rank, song.artist, song.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è  Exo ‚úçÔ∏è\n",
    "\n",
    "Reprendre et adapter le script ci-dessus pour la page :‚ÄØ[https://www.npr.org/2023/12/12/1215355752/best-songs-2023](https://www.npr.org/2023/12/12/1215355752/best-songs-2023)\n",
    "\n",
    "C‚Äôest tr√®s diff√©rent de la page de 2020. La page de 2023‚ÄØest en partie g√©n√©r√©e en JS‚ÄØ√† partir d‚Äôinfos JSON‚ÄØcontenues dans la page HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 gecs \"Dumbest Girl Alive\"\n",
      "6lack \"Since I Have a Lover\"\n",
      "Gracie Abrams \"Where do we go now?\"\n",
      "Tanner Adell \"Buckle Bunny\"\n",
      "Nonso Amadi (feat. Zinoleesky) \"Lock Up\"\n",
      "Anjimile \"The King\"\n",
      "ANOHNI and the Johnsons \"Sliver of Ice\"\n",
      "Omar Apollo \"Ice Slippin\"\n",
      "Al√© Araya (feat. Joseph Chilliams) \"Midnight Gospel\"\n",
      "Darcy James Argue's Secret Society (feat. C√©cile McLorin Salvant) \"Mae West: Advice\"\n",
      "Bad Gyal (feat. Tokischa & Young Miko) \"Chulo pt.2\"\n",
      "The Beaches \"Blame Brett\"\n",
      "Blondshell \"Joiner\"\n",
      "boygenius \"Not Strong Enough\"\n",
      "jaimie branch \"Baba Louie\"\n",
      "Zach Bryan (feat. Kacey Musgraves) \"I Remember Everything\"\n",
      "Bully \"Days Move Slow\"\n",
      "James Casey \"New Bloom\"\n",
      "Louis Cato \"Unsightly Room\"\n",
      "Cautious Clay (feat. Immanuel Wilkins & Ambrose Akinmusire) \"Yesterday's Price\"\n",
      "Central Cee x Dave \"Sprinter\"\n",
      "Tyler Childers \"In Your Love\"\n",
      "Brandy Clark \"Buried\"\n",
      "Luke Combs \"Fast Car\"\n",
      "Confidence Man x Daniel Avery \"On & On (Again)\"\n",
      "Ivan Cornejo \"Donde Est√°s\"\n",
      "corook (feat. Olivia Barton) \"if i were a fish\"\n",
      "Miley Cyrus \"Used To Be Young\"\n",
      "Davido (feat. Musa Keys) \"Unavailable\"\n",
      "Indigo de Souza \"Parking Lot\"\n",
      "Lana Del Rey \"A&W\"\n",
      "Doja Cat \"Agora Hills\"\n",
      "Jeremy Dutcher \"Ancestors Too Young\"\n",
      "Billie Eilish \"What Was I Made For?\"\n",
      "Arvo P√§rt Littlemore Tractus\n",
      "Silvana Estrada \"Milagro y Desastre\"\n",
      "Fall Out Boy \"Fake Out\"\n",
      "FendiDa Rappa (feat. Cardi B) \"Point Me 2\"\n",
      "John Francis Flynn \"Dirty Old Town\"\n",
      "Ben Folds \"Kristine From The 7th Grade\"\n",
      "Peter Gabriel \"Road to Joy\"\n",
      "Moondog \"All is Loneliness\"\n",
      "Gorillaz (feat. Stevie Nicks) \"Oil\"\n",
      "Peggy Gou \"(It Goes Like) Nanana\"\n",
      "Gunna \"fukumean\"\n",
      "Hiromi \"Sonicwonderland\"\n",
      "Horrendous \"Chrysopoeia (The Archeology of Dawn)\"\n",
      "Sam Hunt \"Walmart\"\n",
      "Ice Spice \"Princess Diana\"\n",
      "IDK (feat. Saucy Santana & Jucee Froot) \"Pinot Noir\"\n",
      "Irreversible Entanglements \"Our Land Back\"\n",
      "Jason Isbell and the 400 Unit \"King of Oklahoma\"\n",
      "J Noa \"Autodidacta\"\n",
      "Jam City (feat. Empress Of) \"Wild n Sweet\"\n",
      "Carly Rae Jepsen \"Anything to Be With You\"\n",
      "Durand Jones \"Wait Til I Get Over\"\n",
      "Jungle \"Back on 74\"\n",
      "Noah Kahan (feat. Lizzy McAlpine) \"Call Your Mom\"\n",
      "KAYTRAMIN√â (feat. Amaarae) \"Sossaup\"\n",
      "Kesha \"Eat The Acid\"\n",
      "Killer Mike (feat. Mozzy & Lena Byrd Miles) \"Shed Tears\"\n",
      "Sofia Kourtesis \"Madres\"\n",
      "L'Rain \"Pet Rock\"\n",
      "Latto (feat. Cardi B) \"Put It On Da Floor Again\"\n",
      "Logan Ledger \"Golden State\"\n",
      "Gabe Lee \"Drink the River\"\n",
      "Lil Durk (feat. J. Cole) \"All My Life\"\n",
      "Fenne Lily \"Lights Light Up\"\n",
      "Lil Yachty \"TESLA\"\n",
      "Lydia Loveless \"Sex and Money\"\n",
      "Ashley McBryde \"Single At The Same Time\"\n",
      "Madison McFerrin \"God Herself\"\n",
      "mclusky \"unpopular parts of a pig\"\n",
      "Megan Thee Stallion \"Cobra\"\n",
      "Melenas \"Bang\"\n",
      "Middle Kids \"Highlands\"\n",
      "Mitski \"My Love Mine All Mine\"\n",
      "Victoria Mon√©t \"On My Mama\"\n",
      "Megan Moroney \"I'm Not Pretty\"\n",
      "Myke Towers \"LALA\"\n",
      "NewJeans \"Super Shy\"\n",
      "Jessye Norman \"Tr√§ume\"\n",
      "Obongjayar \"Who Let Him In\"\n",
      "Kassa Overall (feat. Nick Hakim & Theo Croker) \"Make My Way Back Home\"\n",
      "Paris Texas (feat. Kenny Mason) \"DnD\"\n",
      "Hayden Pedigo \"The Happiest Times I Ever Ignored\"\n",
      "Peso Pluma (feat. Eladio Carri√≥n) \"77\"\n",
      "PinkPantheress (feat. Ice Spice) \"Boy‚Äôs a liar Pt. 2\"\n",
      "Pote Baby \"it is what it is\"\n",
      "Ratboys \"The Window\"\n",
      "Olivia Rodrigo \"bad idea right?\"\n",
      "Allison Russell \"Eve Was Black\"\n",
      "C√©cile McLorin Salvant \"M√©lusine\"\n",
      "Sampha \"Spirit 2.0\"\n",
      "ShooterGang Kony (feat. DaBoii & Lil Bean) \"Better Run\"\n",
      "Maria Elena Silva \"Love, If It Is So\"\n",
      "Troye Sivan \"Rush\"\n",
      "Jorja Smith \"GO GO GO\"\n",
      "Esperanza Spalding \"N√£o Ao Marco Temporal\"\n",
      "Spyro (feat. Tiwa Savage) \"Who Is Your Guy? (Remix)\"\n",
      "Sufjan Stevens \"Will Anybody Ever Love Me?\"\n",
      "Susanne Sundf√∏r \"leikara lj√≥√∞\"\n",
      "Sunny War \"Whole\"\n",
      "Teddy Swims \"Lose Control\"\n",
      "Jonathan Tetelman \"Parigi! √à la citt√† dei desideri\"\n",
      "Thank You, I'm Sorry \"Autonomy Shop\"\n",
      "Anna Thorvaldsdottir \"ARCHORA\"\n",
      "Tomb Mold \"Will of Whispers\"\n",
      "Turnstile & BADBADNOTGOOD (feat. Blood Orange) \"Alien Love Call\"\n",
      "Tyla \"Water\"\n",
      "Kali Uchis \"Moonlight\"\n",
      "Vagabon \"Autobahn\"\n",
      "Jessie Ware \"Freak Me Now\"\n",
      "Mimi Webb \"Freezing\"\n",
      "Wednesday \"Chosen to Deserve\"\n",
      "Bella White \"Dishes\"\n",
      "Jess Williamson \"Topanga Two Step\"\n",
      "Yeat \"No mor√´ talk\"\n",
      "Yebba \"Waterfall (I Adore You)\"\n",
      "Young Nudy (feat. 21 Savage) \"Peaches & Eggplants\"\n",
      "The Young'uns \"Jack Merritt's Boots\"\n",
      "Mohamad Zatari Trio \"Black Tea\"\n",
      "Zulu \"Where I'm From\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class Song():\n",
    "    \"\"\"\n",
    "    A‚ÄØsong with 3 infos : artist, title, rank (according to NPR list)\n",
    "    \"\"\"\n",
    "    def __init__(self, artist, title, rank=\"\"):\n",
    "        self.artist = artist\n",
    "        self.title = title\n",
    "        self.rank = rank\n",
    "\n",
    "songs = []\n",
    "url = \"https://www.npr.org/2023/12/12/1215355752/best-songs-2023\"\n",
    "r = requests.get(url)\n",
    "if r:\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    bucket = soup.find('div', attrs={'id': 'res1218689022', 'class': 'bucketwrap'})\n",
    "    json_str = bucket.find('script', attrs={'type': 'application/ld+json'})\n",
    "    json_data = json.loads(json_str.text)\n",
    "    tracks = json_data['track']\n",
    "    for item in tracks:\n",
    "        artist = item['byArtist']['name']\n",
    "        title = item['name']\n",
    "        songs.append(Song(artist, title))\n",
    "    \n",
    "    for song in songs:\n",
    "        print(song.artist, song.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser de l'xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Nous allons travailler sur un fichier au format TEI extrait du corpus *Corpus 14*  \n",
    "PRAXILING - UMR 5267 (PRAXILING) (2014). Corpus 14 [Corpus]. ORTOLANG (Open Resources and TOols for LANGuage) - www.ortolang.fr, https://hdl.handle.net/11403/corpus14/v1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier se nomme ``josephine-1-150119.xml``. Il s'agit d'une lettre d'une femme de soldat √† son √©poux.  \n",
    "Nous allons extraire du fichier TEI les informations suivantes :  \n",
    "- titre (``/TEI/teiHeader/fileDesc/titleStmt/title``)\n",
    "- source (``/TEI/teiHeader/fileDesc/sourceDesc/p``)\n",
    "- contenu de la lettre (``/TEI/text/body``)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pourquoi `lxml` et pas `xml.etree.ElementTree` ? Parce que : [1](http://lxml.de/intro.html) et surtout [2](http://lxml.de/performance.html)  \n",
    "La bonne nouvelle c'est que votre code sera aussi compatible avec `xml.etree.ElementTree` ou `xml.etree.cElementTree` parce que xml utilise l'API ElementTree. Sauf pour la m√©thode `xpath` qui est propre √† `libxml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<cyfunction Comment at 0x7f7856fb3030>\n",
      "{http://www.tei-c.org/ns/1.0}teiHeader\n",
      "<cyfunction Comment at 0x7f7856fb3030>\n",
      "{http://www.tei-c.org/ns/1.0}facsimile\n",
      "{http://www.tei-c.org/ns/1.0}text\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "tree = etree.parse('data/josephine-1-150119.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Parcours des enfants de la racine (commentaires et √©l√©ments)\n",
    "for child in root:\n",
    "    print(child.tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier utilise l'espace de nom TEI : ``<TEI xmlns=\"http://www.tei-c.org/ns/1.0\">``, nous devrons l'indiquer dans nos instructions de recherche.  \n",
    "Voyons √ßa pour le titre (``/TEI/teiHeader/fileDesc/titleStmt/title``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag : {http://www.tei-c.org/ns/1.0}title\n",
      "Texte : Jos√©phine Pouchet √† son √©poux le 19-01-1915 depuis Baillargues\n"
     ]
    }
   ],
   "source": [
    "# la m√©thode find renvoie le premier √©l√©ment qui correspond au chemin argument (ElementPath et non Xpath)\n",
    "title = root.find(\"./tei:teiHeader/tei:fileDesc/tei:titleStmt/tei:title\", namespaces={'tei':\"http://www.tei-c.org/ns/1.0\"})\n",
    "print(\"Tag : {}\".format(title.tag))\n",
    "print(\"Texte : {}\".format(title.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M√™me traitement pour la source :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag : {http://www.tei-c.org/ns/1.0}p\n",
      "Texte : Correspondance de Jos√©phine Pouchet, num√©ris√©e par les Archives D√©partementales de l'H√©rault.\n"
     ]
    }
   ],
   "source": [
    "source = root.find(\"./tei:teiHeader/tei:fileDesc/tei:sourceDesc/tei:p\", namespaces={'tei':\"http://www.tei-c.org/ns/1.0\"})\n",
    "print(\"Tag : {}\".format(source.tag))\n",
    "print(\"Texte : {}\".format(source.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lxml a aussi une m√©thode ``xpath`` qui permet d'utiliser directement des expressions xpath (sans oublier les espace de noms pour notre fichier) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Correspondance de Jos√©phine Pouchet, num√©ris√©e par les Archives D√©partementales de l'H√©rault.\n",
      "Correspondance de Jos√©phine Pouchet, num√©ris√©e par les Archives D√©partementales de l'H√©rault.\n"
     ]
    }
   ],
   "source": [
    "source = root.xpath(\"/tei:TEI/tei:teiHeader/tei:fileDesc/tei:sourceDesc/tei:p\", namespaces={'tei':'http://www.tei-c.org/ns/1.0'})\n",
    "print(type(source)) #xpath retourne une liste\n",
    "print(source[0].text)\n",
    "#ou bien\n",
    "source = root.xpath(\"/tei:TEI/tei:teiHeader/tei:fileDesc/tei:sourceDesc/tei:p/text()\", namespaces={'tei':'http://www.tei-c.org/ns/1.0'})\n",
    "print(source[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le contenu il faut ruser. La difficult√© ici tient √† l'utilisation d'√©lements `<lb/>` de type 'milestones' pour noter les retours √† la ligne :  \n",
    "```xml\n",
    "<p>\n",
    "je reponse a ton aimableux lettres<lb/>\n",
    "que nous a fait plaisir en naprenas<lb/>\n",
    "que tu et enbonne santes car il<lb/>\n",
    "anais de maime pour nous<lb/>\n",
    "</p>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cher Laurent\n",
      "\n",
      "je reponse a ton aimableux lettres\n",
      "\n",
      "cher Laurent je repons a la cartes\n"
     ]
    }
   ],
   "source": [
    "# la m√©thode findall renvoie une liste avec tous les √©l√©ments correspondant au chemin argument\n",
    "body = root.findall(\"./tei:text/tei:body/tei:p\", namespaces={'tei':\"http://www.tei-c.org/ns/1.0\"})\n",
    "for elem in body:\n",
    "    print(elem.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on ne r√©cup√®re que les noeuds text pr√©c√©dant les √©l√©ments `<lb/>`  \n",
    "Une requ√™te `xpath` va nous permettre de r√©cup√©rer tous les noeuds text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Baillargues Le 19 janvier 1915\n",
      "\n",
      "\n",
      "cher Laurent\n",
      "\n",
      "\n",
      "je reponse a ton aimableux lettres\n",
      "que nous a fait plaisir en naprenas\n",
      "que tu et enbonne santes car il\n",
      "anais de maime pour nous\n",
      "\n",
      "\n",
      "cher Laurent je repons a la cartes\n",
      "de ma m√®re quelles et venue au\n",
      "jourdhui pour de faire partire\n",
      "partir un paquet quil aillae\n",
      "les chosette sausice chocolas une\n",
      "paire de chosette pour Louis\n",
      "je pense que vous mager√® ensenbleus\n",
      "tu feras repons a la maison te\n",
      "suite que tu rese vras le paquet\n",
      "je te dirais que ten le midi il\n",
      "fait frois il fait du vent glasais\n",
      "et toi au pas de calais tu nous\n",
      "dit quil pleus mai tu nous parles\n",
      "pas si tu a ases pour te garendir\n",
      "du froit cil te maque quelles chose\n",
      "\n",
      "tu nas que ledire quon de len verras\n",
      "verras tu nous dit que charles ta\n",
      "Ecrie et ta soeux et ta dit que\n",
      "je lui et envoiez la photot\n",
      "plurien a te dire pour le moment\n",
      "que de ten voiez une grose\n",
      "carriese de tous et boutounase\n",
      "de ton petit enge \n",
      "ador√® Albert encorre une foi\n",
      "te plui Milles bais√©es te tous\n",
      "ta fenme pour la vie\n",
      "Josephine Pouchet\n",
      "bien le bonjour de la familles\n",
      "et casimir et de tous le voisin\n",
      "et amie et de marie la perdigailles\n",
      "\n"
     ]
    }
   ],
   "source": [
    "body = root.xpath(\"//tei:text/tei:body//text()\", namespaces={'tei':\"http://www.tei-c.org/ns/1.0\"})\n",
    "for text in body:\n",
    "    print(text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## avec DOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'API `ElementTree` est propre √† Python, `DOM` est une API ind√©pendante d'un langage de programmation. Il existe des impl√©mentations `DOM` dans la plupart des langages de programmation modernes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xml.dom.minidom.Document at 0x7f78542100a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.dom import minidom\n",
    "dom = minidom.parse(\"data/josephine-1-150119.xml\")\n",
    "# l'objet Document\n",
    "dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DOM Element: title at 0x7f785421d2d0>\n",
      "#text\n",
      "Jos√©phine Pouchet √† son √©poux le 19-01-1915 depuis Baillargues\n"
     ]
    }
   ],
   "source": [
    "title = dom.getElementsByTagNameNS(\"http://www.tei-c.org/ns/1.0\", 'title')[0] # un seul √©l√©ment 'title' dans le document\n",
    "print(title) # title est un objet Element, pour acc√®der au contenu textuel il faut r√©cup√©rer le noeud texte\n",
    "print(title.lastChild.nodeName)\n",
    "print(title.lastChild.nodeValue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idem pour la source, sauf qu'on ne peut pas se permettre de rechercher tous les √©l√©ments `p`.  \n",
    "Il faut trouver l'√©l√©ment `p` fils de `sourceDesc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correspondance de Jos√©phine Pouchet, num√©ris√©e par les Archives D√©partementales de l'H√©rault.\n"
     ]
    }
   ],
   "source": [
    "sourceDesc = dom.getElementsByTagNameNS(\"http://www.tei-c.org/ns/1.0\", 'sourceDesc')[0]\n",
    "for node in sourceDesc.childNodes:\n",
    "    if node.localName == \"p\":\n",
    "        print(node.lastChild.nodeValue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Et maintenant le contenu et ses √©l√©ments milestones.  \n",
    "Pour garder la forme vous r√©√©crirez les boucles `for` suivies de `if` en listes en compr√©hension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baillargues Le 19 janvier 1915\n",
      "\n",
      "cher Laurent\n",
      "\n",
      "je reponse a ton aimableux lettres\n",
      "que nous a fait plaisir en naprenas\n",
      "que tu et enbonne santes car il\n",
      "anais de maime pour nous\n",
      "\n",
      "cher Laurent je repons a la cartes\n",
      "de ma m√®re quelles et venue au\n",
      "jourdhui pour de faire \n",
      "partir un paquet quil \n",
      "les chosette sausice chocolas une\n",
      "paire de chosette pour Louis\n",
      "je pense que vous mager√® ensenbleus\n",
      "tu feras repons a la maison te\n",
      "suite que tu rese vras le paquet\n",
      "je te dirais que ten le midi il\n",
      "fait frois il fait du vent glasais\n",
      "et toi au pas de calais tu nous\n",
      "dit quil pleus mai tu nous parles\n",
      "pas si tu a ases pour te garendir\n",
      "du froit cil te maque quelles chose\n",
      "\n",
      "tu nas que ledire quon de len \n",
      "verras tu nous dit que charles ta\n",
      "Ecrie et ta soeux et ta dit que\n",
      "je lui et envoiez la photot\n",
      "plurien a te dire pour le moment\n",
      "que de ten voiez une grose\n",
      "carriese de tous et boutounase\n",
      "de ton petit enge \n",
      "ador√® Albert encorre une foi\n",
      "te plui Milles bais√©es te tous\n",
      "ta fenme pour la vie\n",
      "Josephine Pouchet\n",
      "bien le bonjour de la familles\n",
      "et casimir et de tous le voisin\n",
      "et amie et de marie la perdigailles\n"
     ]
    }
   ],
   "source": [
    "body = dom.getElementsByTagNameNS(\"http://www.tei-c.org/ns/1.0\", 'body')[0]\n",
    "for node in body.childNodes:\n",
    "    if node.localName == \"p\" or \"opener\":\n",
    "        for in_node in node.childNodes:\n",
    "            if in_node.nodeName == \"#text\":\n",
    "                print(in_node.nodeValue, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec lxml et Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"data/josephine-1-150119.xml\") as fp:\n",
    "    soup = BeautifulSoup(fp, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jos√©phine Pouchet √† son √©poux le 19-01-1915 depuis Baillargues'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Correspondance de Jos√©phine Pouchet, num√©ris√©e par les Archives D√©partementales de l'H√©rault.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.sourcedesc.p.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le contenu de la lettre il y a la merveilleuse fonction `get_text()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseparator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstrip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mobject\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x7f787458c700\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Get all child strings of this PageElement, concatenated using the\n",
       "given separator.\n",
       "\n",
       ":param separator: Strings will be concatenated using this separator.\n",
       "\n",
       ":param strip: If True, strings will be stripped before being\n",
       "    concatenated.\n",
       "\n",
       ":param types: A tuple of NavigableString subclasses. Any\n",
       "    strings of a subclass not found in this list will be\n",
       "    ignored. Although there are exceptions, the default\n",
       "    behavior in most cases is to consider only NavigableString\n",
       "    and CData objects. That means no comments, processing\n",
       "    instructions, etc.\n",
       "\n",
       ":return: A string.\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/lib/python3/dist-packages/bs4/element.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "soup.get_text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Baillargues Le 19 janvier 1915\n",
      "\n",
      "\n",
      "cher Laurent\n",
      "\n",
      "\n",
      "je reponse a ton aimableux lettres\n",
      "que nous a fait plaisir en naprenas\n",
      "que tu et enbonne santes car il\n",
      "anais de maime pour nous\n",
      "\n",
      "\n",
      "cher Laurent je repons a la cartes\n",
      "de ma m√®re quelles et venue au\n",
      "jourdhui pour de faire partire\n",
      "partir un paquet quil aillae\n",
      "les chosette sausice chocolas une\n",
      "paire de chosette pour Louis\n",
      "je pense que vous mager√® ensenbleus\n",
      "tu feras repons a la maison te\n",
      "suite que tu rese vras le paquet\n",
      "je te dirais que ten le midi il\n",
      "fait frois il fait du vent glasais\n",
      "et toi au pas de calais tu nous\n",
      "dit quil pleus mai tu nous parles\n",
      "pas si tu a ases pour te garendir\n",
      "du froit cil te maque quelles chose\n",
      "\n",
      "tu nas que ledire quon de len verras\n",
      "verras tu nous dit que charles ta\n",
      "Ecrie et ta soeux et ta dit que\n",
      "je lui et envoiez la photot\n",
      "plurien a te dire pour le moment\n",
      "que de ten voiez une grose\n",
      "carriese de tous et boutounase\n",
      "de ton petit enge \n",
      "ador√® Albert encorre une foi\n",
      "te plui Milles bais√©es te tous\n",
      "ta fenme pour la vie\n",
      "Josephine Pouchet\n",
      "bien le bonjour de la familles\n",
      "et casimir et de tous le voisin\n",
      "et amie et de marie la perdigailles\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = soup.find('text')\n",
    "print(text.getText())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lxml est rapide, Beautiful Soup simple √† utiliser. Le combo diablement efficace.\n",
    "\n",
    "Il y a un autre module super pour le web que nous ne verrons pas ici mais que je me dois de vous indiquer :¬†https://selenium-python.readthedocs.io/  \n",
    "Selenium va vous permettre d'automatiser des actions sur un navigateur. Je vous conseille d'essayer, c'est assez plaisant de voir votre navigateur pilot√© par un script."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
