{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algo 2 – Python\n",
    "\n",
    "## Cours 11\n",
    "\n",
    "###  Master Humanités Numériques du CESR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex et parseurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aujourd’hui deux notions/outils qui pourront vous être utiles : les expressions régulières (regex) et les parseurs. On aura sans doute pas le temps de tout voir en détail, vous pourrez poursuivre par vous-même."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex\n",
    "\n",
    "Le langage formel des expressions régulières (aka regex, *regular expression* en anglais) est un outil puissant et expressif pour la recherche de chaînes de caractères. Il permet de définir un motif (*pattern*) de recherche qui porte sur une chaîne de caractères.\n",
    "\n",
    "Exemples : \n",
    " - \"tubes?\" -> chaîne de caractère \"tube\" ou \"tubes\"\n",
    " - \"[a-z]+eur\\b\" -> chaîne se terminant par \"eur\"\n",
    " - \"\\d{4}-\\d{2}-\\d{2}\" -> date au format ISO 8601 : 2024-03-27 (4 entiers, un tiret, 2 entiers, un tiret, 2 entiers)\n",
    " - …\n",
    "\n",
    "Les expressions régulières sont supportées par la plupart de langages de programmation. Vous les retrouvez dans les éditeurs de texte, dans les traitements de textes et dans pas mal de moteurs de recherche.  \n",
    "Comme c’est très utilisé il existe beaucoup beaucoup de sites bien faits :\n",
    "\n",
    "- [https://regex101.com/](https://regex101.com/) est un site très bien fait pour se former et tester des regex. Allons y tester les exemples vus plus haut.\n",
    "- Il y a de très bons supports de documentation sur les regex, autant en profiter. Par exemple [https://quickref.me/regex.html](https://quickref.me/regex.html)  \n",
    "- Vous pouvez aussi vous auto former avec [https://regexone.com/](https://regexone.com/) ou le magnifique [https://regexcrossword.com](https://regexcrossword.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En python ça se passe avec le module `re` (livré avec la distribution standard) ou `regex` (module externe à installer). On va s’en tenir à `re` ici.\n",
    "\n",
    "- `re` est un module important, vous devez en lire la [documentation](https://docs.python.org/3/library/re.html), absolument\n",
    "- La doc officielle est parfois aride, ce [howto](https://docs.python.org/3/howto/regex.html) rédigé par A.M. Kuchling est plus digeste\n",
    "\n",
    "A minima vous devez connaître les fonctions :\n",
    "\n",
    "- `findall` : trouve toutes les occurences du motif, retourne une liste de chaînes trouvées\n",
    "- `search` : trouve le motif, retourne un objet Match, None sinon\n",
    "- `match` : détermine si le motif est présent au début de la chaîne, retourne un objet Match, None sinon\n",
    "- `split` : découpe une chaîne selon un motif, retourne une liste de chaînes\n",
    "- `sub` : remplace les occurences d'un motif par une chaîne de remplacement\n",
    "- `compile` : compilation d'un motif (pattern), retourne un objet Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pas trouvé\n"
     ]
    }
   ],
   "source": [
    "## Exemple avec \"chaîne se terminant en 'eur'\"\n",
    "\n",
    "import re\n",
    "\n",
    "first_str = \"Avec toutes ces histoires j’ai peur de la clameur de la foule.\"\n",
    "second_str = \"Avec toutes ces histoires j’ai envie d’une tasse de café.\"\n",
    "if re.search(r\"[a-z]+eur\\b\", second_str):\n",
    "    print(\"Trouvé\")\n",
    "else:\n",
    "    print(\"Pas trouvé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objet `Match`\n",
    "`re.search` et `re.match` renvoient un objet de type `re.Match`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.Match"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = re.match(r'\\w', 'spam')\n",
    "type(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le motif est trouvé, l'objet est évalué comme vrai (*truthy*) s'il est testé mais il contient plus d'informations :\n",
    "\n",
    "- `m.group()` la chaîne trouvée (matchée)\n",
    "- `m.start()` l'indice de la position initiale de la chaîne\n",
    "- `m.end()` l'indice de la position finale de la chaîne\n",
    "- `m.span()` le tuple indice début, fin de la chaîne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la\n"
     ]
    }
   ],
   "source": [
    "m = re.search(r\"l[ae]s?\", \"Après la pluie, le beau temps\")\n",
    "print(m.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le motif comporte des groupes de capture :\n",
    "- `m.group(1)` renvoie la chaîne correspond au 1er groupe, etc.\n",
    "- `m.groups()` renvoie un tuple comportant autant d'éléments qu'il y a de groupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('la', 'pluie')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = re.search(r\"(l[ae]s?)\\s(\\w+)\", \"Après la pluie, le beau temps\")\n",
    "m.groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✍️  Exo ✍️\n",
    "\n",
    "- Trouver les noms de personnes ou les noms de lieux dans ces paragraphes :\n",
    "  \n",
    "  « Famed American artist and sculptor Richard Serra, known for turning curving walls of rusting steel and other malleable materials into large-scale pieces of outdoor artwork that are now dotted across the world, died Tuesday at his home in Long Island, New York. He was 85.\n",
    "\n",
    "    Considered one of his generation's most preeminent sculptors, the San Francisco native originally studied painting at Yale University but turned to sculpting in the 1960s, inspired by trips to Europe.\n",
    "\n",
    "    His death was confirmed Tuesday night by his lawyer, John Silberman, whose firm is based in New York. He said the cause of death was pneumonia. »  \n",
    "  (extrait de https://www.npr.org/2024/03/26/1241104634/richard-serra-dead)\n",
    "- Trouver les liens hypertextes dans la page `https://www.reddit.com/r/Python/` et les afficher sous la forme `ancre: url`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Famed', 'American')\n",
      "('Richard', 'Serra')\n",
      "('Long', 'Island')\n",
      "('New', 'York')\n",
      "('San', 'Francisco')\n",
      "('Yale', 'University')\n",
      "('John', 'Silberman')\n",
      "('New', 'York')\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "first_str = \"\"\"Famed American artist and sculptor Richard Serra, known for turning curving walls of rusting steel and other malleable materials into large-scale pieces of outdoor artwork that are now dotted across the world, died Tuesday at his home in Long Island, New York. He was 85.\n",
    "\n",
    "Considered one of his generation's most preeminent sculptors, the San Francisco native originally studied painting at Yale University but tured to sculpting in the 1960s, inspired by trips to Europe.\n",
    "\n",
    "His death was confirmed Tuesday night by his lawyer, John Silberman, whose firm is based in New York. He said the cause of death was pneumonia.\"\"\"\n",
    "\n",
    "for match in re.findall(r\"([A-Z]\\w+) ([A-Z]\\w+)\", first_str):\n",
    "    print(match)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r/LearnPython : /r/LearnPython/\n",
      "Book: Automate the Boring Stuff with Python : https://automatetheboringstuff.com/\n",
      "Book: Think Python : http://www.greenteapress.com/thinkpython2/index.html\n",
      "Book: Fluent Python : https://www.oreilly.com/library/view/fluent-python-2nd/9781492056348/\n",
      "Learn Python on Excercism : https://exercism.org/tracks/python\n",
      "Invent Your Own Computer Games with Python : http://inventwithpython.com/\n",
      "PyMotW: Python Module of the Week : https://pymotw.com/3/\n",
      "Beginner&#39;s Guide Reference : http://wiki.python.org/moin/BeginnersGuide\n",
      "Five life jackets to throw to the new coder (things to do after getting a handle on python) : https://learnbyexample.github.io/curated-resources/python-intermediate/\n",
      "Full Stack Python : http://www.fullstackpython.com/\n",
      "Learn By Example &quot;I know Python basics, what next?&quot; blog post : https://learnbyexample.github.io/curated-resources/python-intermediate/\n",
      "Test-Driven Development with Python : http://www.obeythetestinggoat.com/pages/book.html\n",
      "Program Arcade Games : /http://programarcadegames.com/\n",
      "Python for Scientists and Engineers : http://pythonforengineers.com/python-for-scientists-and-engineers/\n",
      "Dan Bader&#39;s Tips and Trickers : https://dbader.org/\n",
      "JetBrain&#39;s &quot;What does this package do?&quot; series on YouTube : https://www.youtube.com/playlist?list=PLCTHcU1KoD99ZWRvzAGrvF6ZBCrkmZk4t\n",
      "Python Cheatsheet : https://github.com/gto76/python-cheatsheet\n",
      "Python Crash Course cheatsheet : https://ehmatthes.github.io/pcc_3e/cheat_sheets/\n",
      "Scientific Python cheatsheet : https://ipgp.github.io/scientific_python_cheat_sheet/\n",
      "Python RegEx cheatsheet : https://learnbyexample.github.io/python-regex-cheatsheet/\n",
      "Python Discord Resources : https://pythondiscord.com/pages/resources\n",
      "Python Discord&#39;s YouTube channel : https://www.youtube.com/pythondiscord\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get(\"https://www.reddit.com/r/Python/\")\n",
    "if r:\n",
    "    content = r.text\n",
    "    matches = re.findall(r\"href=\\\"([^\\\"]+)\\\">([^<]+?)</a>\", content)\n",
    "    for it in matches:\n",
    "        print(f\"{it[1]} : {it[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parseurs\n",
    "\n",
    "Dans ce notebook nous utiliserons le parseur [lxml](http://lxml.de/) qui est un binding de libxml2 et [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/) \n",
    "\n",
    "Cette partie date de décembre 2020. Je me suis permis de la reprendre telle quelle. L’exemple avec les chansons de NPR fonctionne toujours. Nous allons tout de même essayer de le mettre à jour avec les chansons de 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Parser de l'html\n",
    "\n",
    "Beautiful Soup nous permet de parser simplement du contenu html. Même si le contenu est mal formé, le module bs reconstitue un arbre et offre des fonctions faciles à utiliser pour parcourir l'arbre ou y rechercher des éléments.  \n",
    "Beautiful Soup n'est pas un parseur, il utilise les parseurs et offre une API simplifiée à ses utilisateurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous travaillerons directement avec du contenu en ligne à l'aide du module `requests`. Si vous ne l'avez pas en magasin, installez le.  \n",
    "Décembre c'est le mois des listes, nous nous attacherons à la liste des 100 meilleures chansons de l'année de NPR la radio publique américaine : https://www.npr.org/2020/12/03/931771524/the-100-best-songs-of-2020-page-1  \n",
    "Allez y faire un tour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.npr.org/2020/12/03/931771524/the-100-best-songs-of-2020-page-1\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà nous avons maintenant un objet `soup` de classe Beautiful Soup.  \n",
    "La [doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) est très claire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>NPR's 100 Best Songs Of 2020, Ranked : NPR</title>\n",
      "title\n",
      "NPR's 100 Best Songs Of 2020, Ranked : NPR\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.npr.org/2020/12/03/931771524/the-100-best-songs-of-2020-page-1\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, 'lxml')\n",
    "# je cherche l'élement avec le tag 'title'\n",
    "print(soup.title)\n",
    "# le tag de l'élément\n",
    "print(soup.title.name)\n",
    "# le contenu textuel de l'élément\n",
    "print(soup.title.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche à récupérer la liste des 100 chansons : rang, titre, interprète. Puis on les affichera par ordre croissant.  \n",
    "Il faut inspecter le code source et repérer les élements html et les classes utilisées pour le contentu qui nous intéresse.  \n",
    "Exemple avec le premier, enfin le 100ème : BTS. Dynamite. 🎶 Cos I… I… I'm in the stars tonight 🎸 🎶\n",
    "\n",
    "```html\n",
    "<h6 class=\"edTag\"><a id=\"bts\" class=\"anchor\"> </a>100.</h6>\n",
    "<h3 class=\"edTag\">BTS</h3>\n",
    "<h3 class=\"edTag\">\"Dynamite\"</h3>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100.\n",
      " 99.\n",
      " 98.\n",
      " 97.\n",
      " 96. \n",
      " 95.\n",
      " 94. \n",
      " 93.\n",
      " 92.\n",
      " 91.\n",
      " 90.\n",
      " 89.\n",
      " 88.\n",
      " 87.\n",
      " 86.\n",
      " 85.\n",
      " 84.\n",
      " 83.\n",
      " 82.\n",
      " 81.\n"
     ]
    }
   ],
   "source": [
    "# Exemple pour récupérer les éléments h6 class='edTag'\n",
    "for item in soup.find_all('h6', attrs={'class':'edTag'}):\n",
    "    print(item.text)\n",
    "# on peut aussi utiliser la notation suivante\n",
    "#for item in soup.find_all('h6', class_=\"edTag\"):\n",
    "#    print(item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✍️  Exo ✍️\n",
    "Maintenant à vous de jouer. Il faut parcourir la [doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) pour trouver la fonction qui vous permettra de récupérer les deux éléments h3 suivants et seulement ceux-là. \n",
    "Je vous laisse chercher un peu ![Alt Text](https://media.giphy.com/media/l2SpZkQ0XT1XtKus0/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encore un peu ![on cherche](https://media.giphy.com/media/JO9pi3EeHzyBu5YNMK/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100., BTS, \"Dynamite\"\n",
      " 99., Sturgill Simpson, \"Living The Dream\"\n",
      " 98., Ariana Grande, \"pov\"\n",
      " 97., Busta Rhymes (feat. Kendrick Lamar), \"Look Over Your Shoulder\"\n",
      " 96. , Chicano Batman , \"Color my life\"\n",
      " 95., Tiwa Savage , \"Dangerous Love (DJ Tunez & D3an Remix)\"\n",
      " 94. , Breland (feat. Sam Hunt), \"My Truck (Remix)\"\n",
      " 93., Leon Bridges (feat. Terrace Martin), \"Sweeter\"\n",
      " 92., Yumi Zouma, \"Cool For A Second\"\n",
      " 91., Hayley Williams, \"Simmer\"\n",
      " 90., The 1975, \"If You're Too Shy (Let Me Know)\"\n",
      " 89., Swamp Dogg, \"Billy\"\n",
      " 88., Roomful Of Teeth, \"Just Constellations No. 1, The Opening Constellation (Summer)\"\n",
      " 87., GIVĒON, \"Still Your Best\"\n",
      " 86., Moneybagg Yo, \"Said Sum\"\n",
      " 85., Rita Indiana (feat. Kiko El Crazy), \"Mandinga Times\"\n",
      " 84., Ashnikko (feat. Grimes), \"Cry\"\n",
      " 83., Ultraísta, \"Tin King\"\n",
      " 82., Sweeping Promises, \"Hunger For A Way Out\"\n",
      " 81., Arlo McKinley, \"Die Midwestern\"\n"
     ]
    }
   ],
   "source": [
    "for item in soup.find_all('h6', attrs={'class':'edTag'}):\n",
    "    rank = item.text\n",
    "    h3s = item.find_next_siblings('h3', attrs={'class':'edTag'}, limit=2)\n",
    "    artist = h3s[0].text\n",
    "    title = h3s[1].text\n",
    "    print(f\"{rang}, {artist}, {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✍️  Exo ✍️\n",
    "\n",
    "C'est bien mais pas suffisant. Il reste :\n",
    "  1. nettoyer les rangs, c-a-d supprimmer le point qui traîne à la fin et l'espace des fois.\n",
    "  2. stocker les infos dans une donnée structurée. Utilisez une classe à vous ou plus simple un `namedtuple`\n",
    "  3. faire l'opération pour toutes les pages web afin d'avoir le classement de 1 à 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://www.npr.org/2020/12/03/931771524/the-100-best-songs-of-2020-page-1\",\n",
    "    \"https://www.npr.org/2020/12/03/934634561/the-100-best-songs-of-2020-page-2?utm_source=page1&utm_campaign=next&utm_term=bottom&utm_medium=internal\",\n",
    "    \"https://www.npr.org/2020/12/03/934634607/the-100-best-songs-of-2020-page-3?utm_source=page2&utm_campaign=next&utm_term=bottom&utm_medium=internal\",\n",
    "    \"https://www.npr.org/2020/12/03/934634855/the-100-best-songs-of-2020-page-4?utm_source=page3&utm_campaign=next&utm_term=bottom&utm_medium=internal\",\n",
    "    \"https://www.npr.org/2020/12/03/934634998/the-100-best-songs-of-2020-page-5?utm_source=page4&utm_campaign=next&utm_term=bottom&utm_medium=internal\"\n",
    "]\n",
    "# à vous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Cardi B (feat. Megan Thee Stallion) \"WAP\"\n",
      "2 Christine and the Queens \"People, I've been sad\"\n",
      "3 Megan Thee Stallion (feat. Beyoncé) \"Savage Remix\"\n",
      "4 Mickey Guyton \"Black Like Me\"\n",
      "5 Bad Bunny (feat. Jowell & Randy and Ñengo Flow) \"Safaera\"\n",
      "6 Adrianne Lenker \"anything\"\n",
      "7 Bob Dylan \"Murder Most Foul\"\n",
      "8 Thundercat \"Dragonball Durag\" \n",
      "9 Ana Tijoux \"Antifa Dance\"\n",
      "10 Adia Victoria \"South Gotta Change\"\n",
      "11 Sam Hunt \"Hard to Forget\"\n",
      "12 Jazmine Sullivan \"Lost One\"\n",
      "13 Caylee Hammack \"Small Town Hypocrite\"\n",
      "14 J Hus (feat. Koffee) \"Repeat\"\n",
      "15 Perfume Genius \"On The Floor\"\n",
      "16 Chris Stapleton \"Starting Over\"\n",
      "17 Phoebe Bridgers \"I Know The End\"\n",
      "18 Víkingur Ólafsson \"The Arts and the Hours\"\n",
      "19 Joshua Redman, Brad Mehldau, Christian McBride & Brian Blade \"Right Back Round Again\"\n",
      "20 SZA (feat. Ty Dolla $ign) \"Hit Different\" \n",
      "21 Lil Baby \"The Bigger Picture\"\n",
      "22 Taylor Swift \"invisible string\"\n",
      "23 Childish Gambino \"47.48\"\n",
      "24 Fiona Apple \"I Want You To Love Me\"\n",
      "25 Goodie Mob \"4 My Ppl\"\n",
      "26 The Chicks \"Gaslighter\"\n",
      "27 Noname \"Song 33\"\n",
      "28 Stephanie Lambring \"Joy of Jesus\"\n",
      "29 Lianne La Havas \"Can't Fight\"\n",
      "30 William Prince \"Gospel First Nation\"\n",
      "31 Inbal Segev & London Philharmonic Orchestra \"DANCE, I. when you're broken open\"\n",
      "32 Angelica Garcia \"Agua de Rosa\"\n",
      "33 SAULT \"Wildfires\"\n",
      "34 Jason Isbell and The 400 Unit \"Letting You Go\"\n",
      "35 Kllo  \"Still Here\"\n",
      "36 Immanuel Wilkins  \"Ferguson - An American Tradition\"\n",
      "37 Sun-El Musician (feat. Azana) \"Uhuru\"\n",
      "38 Soccer Mommy \"circle the drain\"\n",
      "39 Dua Lipa  \"Break My Heart\"\n",
      "40 Lil Baby (feat. 42 Dugg) \"We Paid\"\n",
      "41 Tyler Childers \"Long Violent History\"\n",
      "42 Clarice Jensen \"Holy Mother\"\n",
      "43 RMR \"Rascal\"\n",
      "44 Chucky73 & Fetti031 \"Dili\"\n",
      "45 Lakecia Benjamin (feat. Marcus Strickland & Brandee Younger) \"Going Home\"\n",
      "46 Deep Sea Diver \"Stop Pretending\"\n",
      "47 Jayda G \"Both Of Us\"\n",
      "48 Helado Negro (feat. Xenia Rubinos) \"I Fell In Love\"\n",
      "49 Arlo Parks \"Eugene\"\n",
      "50 Romy \"Lifetime\"\n",
      "51 Emma Ruth Rundle & Thou \"Ancestral Recall\"\n",
      "52 Bad Moves \"Local Radio\"\n",
      "53 Jeff Parker \"Go Away\"\n",
      "54 Freddie Gibbs / The Alchemist (feat. Rick Ross) \"Scottie Beam\"\n",
      "55 Shemekia Copeland \"Walk Until I Ride\"\n",
      "56 Steady Holiday \"Living Life\"\n",
      "57 Disclosure (feat. slowthai & Aminé) \"My High\"\n",
      "58 Moses Boyd (feat. Joe Armon-Jones) \"2 Far Gone\"\n",
      "59 Fontaines D.C. \"A Hero's Death\"\n",
      "60 City Girls \"Jobs\"\n",
      "61 Sam Sweeney \"Steppy Downs Road\"\n",
      "62 Moor Jewelry \"Look Alive\"\n",
      "63 Lido Pimienta \"Eso Que Tu Haces\"\n",
      "64 Sarah Jarosz \"Johnny\"\n",
      "65 Rolf Lislevand \"Tombeau pour Mesdemoiselles De Visée\"\n",
      "66 Meet Me @ The Altar \"Garden\"\n",
      "67 La Doña \"Quién Me La Paga\"\n",
      "68 Patrice Roberts \"Tender\"\n",
      "69 Joy Oladokun \"i see america\"\n",
      "70 Aly & AJ \"Joan of Arc on the Dance Floor\"\n",
      "71 Ruston Kelly \"Radio Cloud\"\n",
      "72 Zara McFarlane \"Everything Is Connected\"\n",
      "73 Ashley McBryde \"Hang In There Girl\"\n",
      "74 Xavier Omär  \"SURF\"\n",
      "75 Mireya Ramos  \"Angelitos Negros\"\n",
      "76 Jessie Ware \"Save A Kiss\"\n",
      "77 Hum \"Waves\"\n",
      "78 Terrace Martin, Robert Glasper, 9th Wonder & Kamasi Washington (feat. Phoelix) \"Freeze Tag\"\n",
      "79 BeatKing (feat. Queendom Come) \"Then Leave\"\n",
      "80 Popcaan (feat. Drake & PARTYNEXTDOOR) \"TWIST & TURN\"\n",
      "81 Arlo McKinley \"Die Midwestern\"\n",
      "82 Sweeping Promises \"Hunger For A Way Out\"\n",
      "83 Ultraísta \"Tin King\"\n",
      "84 Ashnikko (feat. Grimes) \"Cry\"\n",
      "85 Rita Indiana (feat. Kiko El Crazy) \"Mandinga Times\"\n",
      "86 Moneybagg Yo \"Said Sum\"\n",
      "87 GIVĒON \"Still Your Best\"\n",
      "88 Roomful Of Teeth \"Just Constellations No. 1, The Opening Constellation (Summer)\"\n",
      "89 Swamp Dogg \"Billy\"\n",
      "90 The 1975 \"If You're Too Shy (Let Me Know)\"\n",
      "91 Hayley Williams \"Simmer\"\n",
      "92 Yumi Zouma \"Cool For A Second\"\n",
      "93 Leon Bridges (feat. Terrace Martin) \"Sweeter\"\n",
      "94 Breland (feat. Sam Hunt) \"My Truck (Remix)\"\n",
      "95 Tiwa Savage  \"Dangerous Love (DJ Tunez & D3an Remix)\"\n",
      "96 Chicano Batman  \"Color my life\"\n",
      "97 Busta Rhymes (feat. Kendrick Lamar) \"Look Over Your Shoulder\"\n",
      "98 Ariana Grande \"pov\"\n",
      "99 Sturgill Simpson \"Living The Dream\"\n",
      "100 BTS \"Dynamite\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Song():\n",
    "    \"\"\"\n",
    "    A song with 3 infos : artist, title, rank (according to NPR list)\n",
    "    \"\"\"\n",
    "    def __init__(self, artist, title, rank):\n",
    "        self.artist = artist\n",
    "        self.title = title\n",
    "        self.rank = rank\n",
    "\n",
    "songs = []\n",
    "for url in urls:\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    for item in soup.find_all('h6', attrs={'class':'edTag'}):\n",
    "        rank = item.text.rstrip(\". \").lstrip()\n",
    "        h3s = item.find_next_siblings('h3', attrs={'class':'edTag'}, limit=2)\n",
    "        artist = h3s[0].text\n",
    "        title = h3s[1].text\n",
    "        songs.append(Song(artist, title, rank))\n",
    "\n",
    "for song in sorted(songs, key=lambda x:int(x.rank)):\n",
    "    print(song.rank, song.artist, song.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✍️  Exo ✍️\n",
    "\n",
    "Reprendre et adapter le script ci-dessus pour la page : [https://www.npr.org/2023/12/12/1215355752/best-songs-2023](https://www.npr.org/2023/12/12/1215355752/best-songs-2023)\n",
    "\n",
    "C’est très différent de la page de 2020. La page de 2023 est en partie générée en JS à partir d’infos JSON contenues dans la page HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 gecs \"Dumbest Girl Alive\"\n",
      "6lack \"Since I Have a Lover\"\n",
      "Gracie Abrams \"Where do we go now?\"\n",
      "Tanner Adell \"Buckle Bunny\"\n",
      "Nonso Amadi (feat. Zinoleesky) \"Lock Up\"\n",
      "Anjimile \"The King\"\n",
      "ANOHNI and the Johnsons \"Sliver of Ice\"\n",
      "Omar Apollo \"Ice Slippin\"\n",
      "Alé Araya (feat. Joseph Chilliams) \"Midnight Gospel\"\n",
      "Darcy James Argue's Secret Society (feat. Cécile McLorin Salvant) \"Mae West: Advice\"\n",
      "Bad Gyal (feat. Tokischa & Young Miko) \"Chulo pt.2\"\n",
      "The Beaches \"Blame Brett\"\n",
      "Blondshell \"Joiner\"\n",
      "boygenius \"Not Strong Enough\"\n",
      "jaimie branch \"Baba Louie\"\n",
      "Zach Bryan (feat. Kacey Musgraves) \"I Remember Everything\"\n",
      "Bully \"Days Move Slow\"\n",
      "James Casey \"New Bloom\"\n",
      "Louis Cato \"Unsightly Room\"\n",
      "Cautious Clay (feat. Immanuel Wilkins & Ambrose Akinmusire) \"Yesterday's Price\"\n",
      "Central Cee x Dave \"Sprinter\"\n",
      "Tyler Childers \"In Your Love\"\n",
      "Brandy Clark \"Buried\"\n",
      "Luke Combs \"Fast Car\"\n",
      "Confidence Man x Daniel Avery \"On & On (Again)\"\n",
      "Ivan Cornejo \"Donde Estás\"\n",
      "corook (feat. Olivia Barton) \"if i were a fish\"\n",
      "Miley Cyrus \"Used To Be Young\"\n",
      "Davido (feat. Musa Keys) \"Unavailable\"\n",
      "Indigo de Souza \"Parking Lot\"\n",
      "Lana Del Rey \"A&W\"\n",
      "Doja Cat \"Agora Hills\"\n",
      "Jeremy Dutcher \"Ancestors Too Young\"\n",
      "Billie Eilish \"What Was I Made For?\"\n",
      "Arvo Pärt Littlemore Tractus\n",
      "Silvana Estrada \"Milagro y Desastre\"\n",
      "Fall Out Boy \"Fake Out\"\n",
      "FendiDa Rappa (feat. Cardi B) \"Point Me 2\"\n",
      "John Francis Flynn \"Dirty Old Town\"\n",
      "Ben Folds \"Kristine From The 7th Grade\"\n",
      "Peter Gabriel \"Road to Joy\"\n",
      "Moondog \"All is Loneliness\"\n",
      "Gorillaz (feat. Stevie Nicks) \"Oil\"\n",
      "Peggy Gou \"(It Goes Like) Nanana\"\n",
      "Gunna \"fukumean\"\n",
      "Hiromi \"Sonicwonderland\"\n",
      "Horrendous \"Chrysopoeia (The Archeology of Dawn)\"\n",
      "Sam Hunt \"Walmart\"\n",
      "Ice Spice \"Princess Diana\"\n",
      "IDK (feat. Saucy Santana & Jucee Froot) \"Pinot Noir\"\n",
      "Irreversible Entanglements \"Our Land Back\"\n",
      "Jason Isbell and the 400 Unit \"King of Oklahoma\"\n",
      "J Noa \"Autodidacta\"\n",
      "Jam City (feat. Empress Of) \"Wild n Sweet\"\n",
      "Carly Rae Jepsen \"Anything to Be With You\"\n",
      "Durand Jones \"Wait Til I Get Over\"\n",
      "Jungle \"Back on 74\"\n",
      "Noah Kahan (feat. Lizzy McAlpine) \"Call Your Mom\"\n",
      "KAYTRAMINÉ (feat. Amaarae) \"Sossaup\"\n",
      "Kesha \"Eat The Acid\"\n",
      "Killer Mike (feat. Mozzy & Lena Byrd Miles) \"Shed Tears\"\n",
      "Sofia Kourtesis \"Madres\"\n",
      "L'Rain \"Pet Rock\"\n",
      "Latto (feat. Cardi B) \"Put It On Da Floor Again\"\n",
      "Logan Ledger \"Golden State\"\n",
      "Gabe Lee \"Drink the River\"\n",
      "Lil Durk (feat. J. Cole) \"All My Life\"\n",
      "Fenne Lily \"Lights Light Up\"\n",
      "Lil Yachty \"TESLA\"\n",
      "Lydia Loveless \"Sex and Money\"\n",
      "Ashley McBryde \"Single At The Same Time\"\n",
      "Madison McFerrin \"God Herself\"\n",
      "mclusky \"unpopular parts of a pig\"\n",
      "Megan Thee Stallion \"Cobra\"\n",
      "Melenas \"Bang\"\n",
      "Middle Kids \"Highlands\"\n",
      "Mitski \"My Love Mine All Mine\"\n",
      "Victoria Monét \"On My Mama\"\n",
      "Megan Moroney \"I'm Not Pretty\"\n",
      "Myke Towers \"LALA\"\n",
      "NewJeans \"Super Shy\"\n",
      "Jessye Norman \"Träume\"\n",
      "Obongjayar \"Who Let Him In\"\n",
      "Kassa Overall (feat. Nick Hakim & Theo Croker) \"Make My Way Back Home\"\n",
      "Paris Texas (feat. Kenny Mason) \"DnD\"\n",
      "Hayden Pedigo \"The Happiest Times I Ever Ignored\"\n",
      "Peso Pluma (feat. Eladio Carrión) \"77\"\n",
      "PinkPantheress (feat. Ice Spice) \"Boy’s a liar Pt. 2\"\n",
      "Pote Baby \"it is what it is\"\n",
      "Ratboys \"The Window\"\n",
      "Olivia Rodrigo \"bad idea right?\"\n",
      "Allison Russell \"Eve Was Black\"\n",
      "Cécile McLorin Salvant \"Mélusine\"\n",
      "Sampha \"Spirit 2.0\"\n",
      "ShooterGang Kony (feat. DaBoii & Lil Bean) \"Better Run\"\n",
      "Maria Elena Silva \"Love, If It Is So\"\n",
      "Troye Sivan \"Rush\"\n",
      "Jorja Smith \"GO GO GO\"\n",
      "Esperanza Spalding \"Não Ao Marco Temporal\"\n",
      "Spyro (feat. Tiwa Savage) \"Who Is Your Guy? (Remix)\"\n",
      "Sufjan Stevens \"Will Anybody Ever Love Me?\"\n",
      "Susanne Sundfør \"leikara ljóð\"\n",
      "Sunny War \"Whole\"\n",
      "Teddy Swims \"Lose Control\"\n",
      "Jonathan Tetelman \"Parigi! È la città dei desideri\"\n",
      "Thank You, I'm Sorry \"Autonomy Shop\"\n",
      "Anna Thorvaldsdottir \"ARCHORA\"\n",
      "Tomb Mold \"Will of Whispers\"\n",
      "Turnstile & BADBADNOTGOOD (feat. Blood Orange) \"Alien Love Call\"\n",
      "Tyla \"Water\"\n",
      "Kali Uchis \"Moonlight\"\n",
      "Vagabon \"Autobahn\"\n",
      "Jessie Ware \"Freak Me Now\"\n",
      "Mimi Webb \"Freezing\"\n",
      "Wednesday \"Chosen to Deserve\"\n",
      "Bella White \"Dishes\"\n",
      "Jess Williamson \"Topanga Two Step\"\n",
      "Yeat \"No morë talk\"\n",
      "Yebba \"Waterfall (I Adore You)\"\n",
      "Young Nudy (feat. 21 Savage) \"Peaches & Eggplants\"\n",
      "The Young'uns \"Jack Merritt's Boots\"\n",
      "Mohamad Zatari Trio \"Black Tea\"\n",
      "Zulu \"Where I'm From\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class Song():\n",
    "    \"\"\"\n",
    "    A song with 3 infos : artist, title, rank (according to NPR list)\n",
    "    \"\"\"\n",
    "    def __init__(self, artist, title, rank=\"\"):\n",
    "        self.artist = artist\n",
    "        self.title = title\n",
    "        self.rank = rank\n",
    "\n",
    "songs = []\n",
    "url = \"https://www.npr.org/2023/12/12/1215355752/best-songs-2023\"\n",
    "r = requests.get(url)\n",
    "if r:\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    bucket = soup.find('div', attrs={'id': 'res1218689022', 'class': 'bucketwrap'})\n",
    "    json_str = bucket.find('script', attrs={'type': 'application/ld+json'})\n",
    "    json_data = json.loads(json_str.text)\n",
    "    tracks = json_data['track']\n",
    "    for item in tracks:\n",
    "        artist = item['byArtist']['name']\n",
    "        title = item['name']\n",
    "        songs.append(Song(artist, title))\n",
    "    \n",
    "    for song in songs:\n",
    "        print(song.artist, song.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser de l'xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Nous allons travailler sur un fichier au format TEI extrait du corpus *Corpus 14*  \n",
    "PRAXILING - UMR 5267 (PRAXILING) (2014). Corpus 14 [Corpus]. ORTOLANG (Open Resources and TOols for LANGuage) - www.ortolang.fr, https://hdl.handle.net/11403/corpus14/v1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier se nomme ``josephine-1-150119.xml``. Il s'agit d'une lettre d'une femme de soldat à son époux.  \n",
    "Nous allons extraire du fichier TEI les informations suivantes :  \n",
    "- titre (``/TEI/teiHeader/fileDesc/titleStmt/title``)\n",
    "- source (``/TEI/teiHeader/fileDesc/sourceDesc/p``)\n",
    "- contenu de la lettre (``/TEI/text/body``)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pourquoi `lxml` et pas `xml.etree.ElementTree` ? Parce que : [1](http://lxml.de/intro.html) et surtout [2](http://lxml.de/performance.html)  \n",
    "La bonne nouvelle c'est que votre code sera aussi compatible avec `xml.etree.ElementTree` ou `xml.etree.cElementTree` parce que xml utilise l'API ElementTree. Sauf pour la méthode `xpath` qui est propre à `libxml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<cyfunction Comment at 0x7f7856fb3030>\n",
      "{http://www.tei-c.org/ns/1.0}teiHeader\n",
      "<cyfunction Comment at 0x7f7856fb3030>\n",
      "{http://www.tei-c.org/ns/1.0}facsimile\n",
      "{http://www.tei-c.org/ns/1.0}text\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "tree = etree.parse('data/josephine-1-150119.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Parcours des enfants de la racine (commentaires et éléments)\n",
    "for child in root:\n",
    "    print(child.tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier utilise l'espace de nom TEI : ``<TEI xmlns=\"http://www.tei-c.org/ns/1.0\">``, nous devrons l'indiquer dans nos instructions de recherche.  \n",
    "Voyons ça pour le titre (``/TEI/teiHeader/fileDesc/titleStmt/title``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag : {http://www.tei-c.org/ns/1.0}title\n",
      "Texte : Joséphine Pouchet à son époux le 19-01-1915 depuis Baillargues\n"
     ]
    }
   ],
   "source": [
    "# la méthode find renvoie le premier élément qui correspond au chemin argument (ElementPath et non Xpath)\n",
    "title = root.find(\"./tei:teiHeader/tei:fileDesc/tei:titleStmt/tei:title\", namespaces={'tei':\"http://www.tei-c.org/ns/1.0\"})\n",
    "print(\"Tag : {}\".format(title.tag))\n",
    "print(\"Texte : {}\".format(title.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même traitement pour la source :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag : {http://www.tei-c.org/ns/1.0}p\n",
      "Texte : Correspondance de Joséphine Pouchet, numérisée par les Archives Départementales de l'Hérault.\n"
     ]
    }
   ],
   "source": [
    "source = root.find(\"./tei:teiHeader/tei:fileDesc/tei:sourceDesc/tei:p\", namespaces={'tei':\"http://www.tei-c.org/ns/1.0\"})\n",
    "print(\"Tag : {}\".format(source.tag))\n",
    "print(\"Texte : {}\".format(source.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lxml a aussi une méthode ``xpath`` qui permet d'utiliser directement des expressions xpath (sans oublier les espace de noms pour notre fichier) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Correspondance de Joséphine Pouchet, numérisée par les Archives Départementales de l'Hérault.\n",
      "Correspondance de Joséphine Pouchet, numérisée par les Archives Départementales de l'Hérault.\n"
     ]
    }
   ],
   "source": [
    "source = root.xpath(\"/tei:TEI/tei:teiHeader/tei:fileDesc/tei:sourceDesc/tei:p\", namespaces={'tei':'http://www.tei-c.org/ns/1.0'})\n",
    "print(type(source)) #xpath retourne une liste\n",
    "print(source[0].text)\n",
    "#ou bien\n",
    "source = root.xpath(\"/tei:TEI/tei:teiHeader/tei:fileDesc/tei:sourceDesc/tei:p/text()\", namespaces={'tei':'http://www.tei-c.org/ns/1.0'})\n",
    "print(source[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le contenu il faut ruser. La difficulté ici tient à l'utilisation d'élements `<lb/>` de type 'milestones' pour noter les retours à la ligne :  \n",
    "```xml\n",
    "<p>\n",
    "je reponse a ton aimableux lettres<lb/>\n",
    "que nous a fait plaisir en naprenas<lb/>\n",
    "que tu et enbonne santes car il<lb/>\n",
    "anais de maime pour nous<lb/>\n",
    "</p>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cher Laurent\n",
      "\n",
      "je reponse a ton aimableux lettres\n",
      "\n",
      "cher Laurent je repons a la cartes\n"
     ]
    }
   ],
   "source": [
    "# la méthode findall renvoie une liste avec tous les éléments correspondant au chemin argument\n",
    "body = root.findall(\"./tei:text/tei:body/tei:p\", namespaces={'tei':\"http://www.tei-c.org/ns/1.0\"})\n",
    "for elem in body:\n",
    "    print(elem.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on ne récupère que les noeuds text précédant les éléments `<lb/>`  \n",
    "Une requête `xpath` va nous permettre de récupérer tous les noeuds text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Baillargues Le 19 janvier 1915\n",
      "\n",
      "\n",
      "cher Laurent\n",
      "\n",
      "\n",
      "je reponse a ton aimableux lettres\n",
      "que nous a fait plaisir en naprenas\n",
      "que tu et enbonne santes car il\n",
      "anais de maime pour nous\n",
      "\n",
      "\n",
      "cher Laurent je repons a la cartes\n",
      "de ma mère quelles et venue au\n",
      "jourdhui pour de faire partire\n",
      "partir un paquet quil aillae\n",
      "les chosette sausice chocolas une\n",
      "paire de chosette pour Louis\n",
      "je pense que vous magerè ensenbleus\n",
      "tu feras repons a la maison te\n",
      "suite que tu rese vras le paquet\n",
      "je te dirais que ten le midi il\n",
      "fait frois il fait du vent glasais\n",
      "et toi au pas de calais tu nous\n",
      "dit quil pleus mai tu nous parles\n",
      "pas si tu a ases pour te garendir\n",
      "du froit cil te maque quelles chose\n",
      "\n",
      "tu nas que ledire quon de len verras\n",
      "verras tu nous dit que charles ta\n",
      "Ecrie et ta soeux et ta dit que\n",
      "je lui et envoiez la photot\n",
      "plurien a te dire pour le moment\n",
      "que de ten voiez une grose\n",
      "carriese de tous et boutounase\n",
      "de ton petit enge \n",
      "adorè Albert encorre une foi\n",
      "te plui Milles baisées te tous\n",
      "ta fenme pour la vie\n",
      "Josephine Pouchet\n",
      "bien le bonjour de la familles\n",
      "et casimir et de tous le voisin\n",
      "et amie et de marie la perdigailles\n",
      "\n"
     ]
    }
   ],
   "source": [
    "body = root.xpath(\"//tei:text/tei:body//text()\", namespaces={'tei':\"http://www.tei-c.org/ns/1.0\"})\n",
    "for text in body:\n",
    "    print(text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## avec DOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'API `ElementTree` est propre à Python, `DOM` est une API indépendante d'un langage de programmation. Il existe des implémentations `DOM` dans la plupart des langages de programmation modernes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xml.dom.minidom.Document at 0x7f78542100a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.dom import minidom\n",
    "dom = minidom.parse(\"data/josephine-1-150119.xml\")\n",
    "# l'objet Document\n",
    "dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DOM Element: title at 0x7f785421d2d0>\n",
      "#text\n",
      "Joséphine Pouchet à son époux le 19-01-1915 depuis Baillargues\n"
     ]
    }
   ],
   "source": [
    "title = dom.getElementsByTagNameNS(\"http://www.tei-c.org/ns/1.0\", 'title')[0] # un seul élément 'title' dans le document\n",
    "print(title) # title est un objet Element, pour accèder au contenu textuel il faut récupérer le noeud texte\n",
    "print(title.lastChild.nodeName)\n",
    "print(title.lastChild.nodeValue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idem pour la source, sauf qu'on ne peut pas se permettre de rechercher tous les éléments `p`.  \n",
    "Il faut trouver l'élément `p` fils de `sourceDesc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correspondance de Joséphine Pouchet, numérisée par les Archives Départementales de l'Hérault.\n"
     ]
    }
   ],
   "source": [
    "sourceDesc = dom.getElementsByTagNameNS(\"http://www.tei-c.org/ns/1.0\", 'sourceDesc')[0]\n",
    "for node in sourceDesc.childNodes:\n",
    "    if node.localName == \"p\":\n",
    "        print(node.lastChild.nodeValue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Et maintenant le contenu et ses éléments milestones.  \n",
    "Pour garder la forme vous réécrirez les boucles `for` suivies de `if` en listes en compréhension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baillargues Le 19 janvier 1915\n",
      "\n",
      "cher Laurent\n",
      "\n",
      "je reponse a ton aimableux lettres\n",
      "que nous a fait plaisir en naprenas\n",
      "que tu et enbonne santes car il\n",
      "anais de maime pour nous\n",
      "\n",
      "cher Laurent je repons a la cartes\n",
      "de ma mère quelles et venue au\n",
      "jourdhui pour de faire \n",
      "partir un paquet quil \n",
      "les chosette sausice chocolas une\n",
      "paire de chosette pour Louis\n",
      "je pense que vous magerè ensenbleus\n",
      "tu feras repons a la maison te\n",
      "suite que tu rese vras le paquet\n",
      "je te dirais que ten le midi il\n",
      "fait frois il fait du vent glasais\n",
      "et toi au pas de calais tu nous\n",
      "dit quil pleus mai tu nous parles\n",
      "pas si tu a ases pour te garendir\n",
      "du froit cil te maque quelles chose\n",
      "\n",
      "tu nas que ledire quon de len \n",
      "verras tu nous dit que charles ta\n",
      "Ecrie et ta soeux et ta dit que\n",
      "je lui et envoiez la photot\n",
      "plurien a te dire pour le moment\n",
      "que de ten voiez une grose\n",
      "carriese de tous et boutounase\n",
      "de ton petit enge \n",
      "adorè Albert encorre une foi\n",
      "te plui Milles baisées te tous\n",
      "ta fenme pour la vie\n",
      "Josephine Pouchet\n",
      "bien le bonjour de la familles\n",
      "et casimir et de tous le voisin\n",
      "et amie et de marie la perdigailles\n"
     ]
    }
   ],
   "source": [
    "body = dom.getElementsByTagNameNS(\"http://www.tei-c.org/ns/1.0\", 'body')[0]\n",
    "for node in body.childNodes:\n",
    "    if node.localName == \"p\" or \"opener\":\n",
    "        for in_node in node.childNodes:\n",
    "            if in_node.nodeName == \"#text\":\n",
    "                print(in_node.nodeValue, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec lxml et Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"data/josephine-1-150119.xml\") as fp:\n",
    "    soup = BeautifulSoup(fp, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Joséphine Pouchet à son époux le 19-01-1915 depuis Baillargues'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Correspondance de Joséphine Pouchet, numérisée par les Archives Départementales de l'Hérault.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.sourcedesc.p.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le contenu de la lettre il y a la merveilleuse fonction `get_text()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseparator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstrip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mobject\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x7f787458c700\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Get all child strings of this PageElement, concatenated using the\n",
       "given separator.\n",
       "\n",
       ":param separator: Strings will be concatenated using this separator.\n",
       "\n",
       ":param strip: If True, strings will be stripped before being\n",
       "    concatenated.\n",
       "\n",
       ":param types: A tuple of NavigableString subclasses. Any\n",
       "    strings of a subclass not found in this list will be\n",
       "    ignored. Although there are exceptions, the default\n",
       "    behavior in most cases is to consider only NavigableString\n",
       "    and CData objects. That means no comments, processing\n",
       "    instructions, etc.\n",
       "\n",
       ":return: A string.\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/lib/python3/dist-packages/bs4/element.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "soup.get_text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Baillargues Le 19 janvier 1915\n",
      "\n",
      "\n",
      "cher Laurent\n",
      "\n",
      "\n",
      "je reponse a ton aimableux lettres\n",
      "que nous a fait plaisir en naprenas\n",
      "que tu et enbonne santes car il\n",
      "anais de maime pour nous\n",
      "\n",
      "\n",
      "cher Laurent je repons a la cartes\n",
      "de ma mère quelles et venue au\n",
      "jourdhui pour de faire partire\n",
      "partir un paquet quil aillae\n",
      "les chosette sausice chocolas une\n",
      "paire de chosette pour Louis\n",
      "je pense que vous magerè ensenbleus\n",
      "tu feras repons a la maison te\n",
      "suite que tu rese vras le paquet\n",
      "je te dirais que ten le midi il\n",
      "fait frois il fait du vent glasais\n",
      "et toi au pas de calais tu nous\n",
      "dit quil pleus mai tu nous parles\n",
      "pas si tu a ases pour te garendir\n",
      "du froit cil te maque quelles chose\n",
      "\n",
      "tu nas que ledire quon de len verras\n",
      "verras tu nous dit que charles ta\n",
      "Ecrie et ta soeux et ta dit que\n",
      "je lui et envoiez la photot\n",
      "plurien a te dire pour le moment\n",
      "que de ten voiez une grose\n",
      "carriese de tous et boutounase\n",
      "de ton petit enge \n",
      "adorè Albert encorre une foi\n",
      "te plui Milles baisées te tous\n",
      "ta fenme pour la vie\n",
      "Josephine Pouchet\n",
      "bien le bonjour de la familles\n",
      "et casimir et de tous le voisin\n",
      "et amie et de marie la perdigailles\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = soup.find('text')\n",
    "print(text.getText())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lxml est rapide, Beautiful Soup simple à utiliser. Le combo diablement efficace.\n",
    "\n",
    "Il y a un autre module super pour le web que nous ne verrons pas ici mais que je me dois de vous indiquer : https://selenium-python.readthedocs.io/  \n",
    "Selenium va vous permettre d'automatiser des actions sur un navigateur. Je vous conseille d'essayer, c'est assez plaisant de voir votre navigateur piloté par un script."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
